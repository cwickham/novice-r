# Development {#r-development}

```{r r-development-setup, include=FALSE}
source("_common.R")
```

## Questions {#r-dev-questions}

```{r child="questions/r-development.md"}
```

## Functions {#r-dev-functions}

Functions are like recipes. You give a few ingredients as input to a function,
and it will generate an output based on these ingredients. Just as when
following a recipe, both the ingredients and the instructions will influence
the final result.

In R, the "ingredients" to a function are called arguments, and the output is
referred to as the "return value". A
function does not technically need to return a value, but often does.
Functions allow code chunks to be reused in a more readable and reproducible way
than cutting and pasting several lines of code. E.g. if our data
analysis code is broken down into several functions, we could readily use it with many
different data sets by changing the input argument for the data, while leaving the rest of
the code the same.

Well chosen function names also clarifies the flow of analysis. For example,
imagine that you open a file with the following lines of code within it.

```{r, eval=FALSE}
images <- read_in_images(file_paths)
gray_images <- convert_to_grayscale(images)
brightest_image <- find_brightest_image(gray_images)
```

Just by looking at the function names, it might be fairly clear what this code is intended
for and its main flow of operations is readily apparent. Inside each of
these functions there might be 10-20 lines of code, so if we had not 
modularized the code into separate functions with well chosen names, it
would take longer to understand its overall purpose since there
would be 30-60 lines of code to read instead of just three.

### Creating functions {#r-dev-creating-functions}

In R, everything that has an action ("does something") is a function. Functions
are the engines that move all analyses and programming in R. Creating functions
are also fairly straightforward (though not always easy to get right).

When making functions, there is always a fundamental structure to them:

1. Give a name to the function (e.g. `read_png_files()`).
2. Start the function call with `function()` and assign it to the name with
`<-`. This tells R that the name is now a function object.
3. Optionally provide arguments to the function call, for instance
`function(arg1, arg2, arg3)`. 
4. Fill out the body of the function with the arguments (if any) contained
inside and other code that does some action.
5. Optionally, but strongly encouraged, use `return()` to indicate what you want 
the function to output.

While there is no minimum or maximum number of arguments you can provide for a
function (e.g. you could have zero or dozens of arguments), its good practice
for yourself and for others if you have as few arguments as necessary for your
code to do what you want it to.

So, the structure is:

```{r function-structure, eval=FALSE}
name <- function(arg1, arg2) {
    # body of function
    ... code ....
    return(output)
}
```

... and a simple example:

```{r create-add-function}
sum_two_numbers <- function(num1, num2) {
    added <- num1 + num2
    return(added)
}
```

This function takes two input parameters, `num1` and `num2`, and returns
their sum. Just as with variable names, function names are preferably written
in `snake_case` (see the [style guide](#style) for details). Try to avoid 
using already existing R function names, 

A simple way of doing that is by

You can use the new function by running the above code and writing out your new 
function, with arguments given to it.

```{r call-function}
sum_two_numbers(1, 2)
```

The function name is fairly good... `add_nums` can be read as "add numbers".



To execute the operations listed in the function, we can call the function
and pass the two numbers we want to add as the arguments to the function.

```{python}
sum_two_numbers(2, 5)
```

The returned value can be assigned to a variable:

```{python}
number_sum = sum_two_numbers(2, 5)
number_sum
```

A more versatile function could add any amount of numbers together and return
their sum:

```{python}
def sum_all_numbers(list_of_numbers):
    number_sum = 0
    for number in list_of_numbers:
        number_sum += number
    return number_sum

sum_all_numbers([1, 2, 3,])
```

A function can also return multiple outputs, e.g. we can return the number of
elements in addition to their sum:

```{python}
def sum_and_len_all_numbers(list_of_numbers):
    number_sum = 0
    number_len = 0
    for number in list_of_numbers:
        number_sum += number
        number_len += 1
    return number_sum, number_len
```

To capture the output, we can either assign to a single name, a tuple, or
assign both at the same time to different variables.

```{python}
sum_and_len_of_numbers = sum_and_len_all_numbers([1, 2, 3])
sum_and_len_of_numbers
```

```{python}
sum_of_numbers, len_of_numbers = sum_and_len_all_numbers([1, 2, 3])
sum_of_numbers
```

```{python}
len_of_numbers
```

Note that when we defined the function `sum_two_numbers()`, we referred to
`num1` and `num2` as *parameters*, while we refer to the numbers we pass to the
function call (`2` and `5` above) as *arguments*. Although this might sound
confusing at first, it is a standard followed by many programming languages so
it is useful to get accustomed to this terminology.

#### Function composition {#r-dev-function-composition}

Combining functions is referred to as function composition. This practice
allows us to write functions that perform one specific task and then combine
them for more complicated tasks, which makes code more readable and easier to
debug. By composing a function from the built-in `len()` and `sum()` functions,
we can create a more succinct and easier to read version of our previous
function `sum_and_len_all_numbers()`.

```{python}
def sum_and_len(list_of_numbers):
    return sum(list_of_numbers), len(list_of_numbers)
```

#### Positional and keyword arguments {#r-dev-positional-and-keyword-arguments}

Up until now, our function calls have included just enough arguments to assign
one to each of the function parameters. The assignment has been based on the
position of the arguments in the function call and therefore these are called
positional arguments. We could be more explicit and include the parameter name
in the assignment.

```{python}
sum_two_numbers(num1=2, num2=5)
```

The arguments are now referred to as keyword arguments and has the advantage
that they can be specified in any order.

```{python}
sum_two_numbers(num2=5, num1=2)
```

#### Defining default values {#r-dev-defining-default-values}

Above, we have specified a value for every argument in each function call. This
is manageable when functions have few parameters, but it can get tedious for
functions with many parameters. Defining default values for select parameters
can facilitate working with complex functions by reducing the number of
arguments that need to be defined when calling the function and guide users to
good default choices for the parameters without requiring in-depth knowledge of
each parameter. As an example, we can modify `sum_two_numbers()` to optionally
return the two input arguments.

```{python}
def sum_two_numbers(num1, num2, return_input=False):
    if return_input:
        return num1, num2, num1 + num2
    else:
        return num1 + num2
```

By default the function will work just as previously.

```{python}
sum_two_numbers(2, 5)
```

But we now also have the option to return the input numbers.

```{python}
sum_two_numbers(2, 5, return_input=True)
```

Since the arguments are given in the same order as in the function definition,
we could have left out the `return_input=` part and just written `True` in the
third position.

#### Function documentation {#r-dev-function-documentation}

Functions might appear self-explanatory when they are being written, but it is
essential that there is proper documentation describing what the function does
and what types of arguments should be in the input. This helps other people who
are reading your code and also your future self that will be reusing these
functions.

In Python, a function is documented in its docstring, which is a multiline
Python string immediately following the function definition. It is surrounded
by triple quotes (either single or double) and can look like this.

```{python}
def sum_two_numbers(num1, num2):
    '''
    Add two numbers

    Parameters
    ----------
    num1: int, float
        The first number to be added.
    num2: int, float
        The second number to be added.

    Returns
    -------
    int, float
        Sum of the two numbers.
    '''

    return num1 + num2
```

The above docstring convention is referred to as the `numpy` docstring format.
There are other conventions, but here we recommended using the `numpy`
docstring format since it is easy to read for complex functions with many
arguments and used by many integral data science Python packages. It is
described in great detail in the [numpy][numpy-docstring] and
[pandas][pandas-docstring] documentation.

Docstrings constitute the text that show up in the function help message, so
it is important that these are well-written and helpful for the reader.

```{python}
help(sum_two_numbers)
```

This is the same text that is displayed in the Spyder help pane, where it is
rendered as markdown for rich display with typefaces, headings, etc.

![Rich rendering of the docstring in Spyder](figures/r-development/docstring-spyder.png)

Spyder includes a convenient function to automatically generate docstring
templates. Once you have written the function signature and typed out the first
triple quote for the docstring, there will be a small pop-up window that reads
"Generate docstring". Click it or press enter and a `numpy` docstring template
will be created based on the parameters in the function signature.

## How to make programs indicate that something has gone wrong? {#r-dev-how-to-make-programs-indicate-that-something-has-gone-wrong}

When performing programmatic data analysis, we need to both ensure that our
code runs correctly and that it carries out the intended tasks. The Python
interpreter will help us with the first part; if a part of the code is not
valid, an error will be raised with a message that helps us trace back what
part of the code is not correct.

### Ducktyping - relying on Python to detect unexpected behavior {#r-dev-ducktyping-relying-on-Python-to-detect-unexpected-behavior}

In our function `sum_two_numbers()`, we could explicitly check that the input
arguments are numerical. However, explicitly checking the type of each input
parameter quickly becomes tedious and can make functions less readable,
especially as they grow more complex. An alternative approach is to try to
perform the intended operations on the input parameters and rely on that Python
will raise an error if they are of the wrong type.

```{python error=TRUE}
sum_two_numbers(5, 'six')
```

The raised error contains a helpful message that alerts us to what went wrong;
`string` objects cannot be added to `int` objects in Python. If the input
variables behave correctly then they probably are of the correct types and no
explicit checking is needed. This approach is often referred to as "ducktyping"
because it makes assumptions on the type of variable based on its behavior, just
like the saying

> If it looks like a duck, swims like a duck, and quacks like a duck, then it
> probably is a duck.

### Assertions - explicitly checking for unexpected behavior {#r-dev-assertions-explicitly-checking-for-unexpected-behavior}

Ducktyping is useful to catch anything that raises an error in Python, but
sometimes we might want to stop the code execution for reasons other than a
technical Python error. Examples of this include when you have performed a
specific operation that you know should give output of a certain shape and to
check if a variable is within an allowed range. The `assert` statement allows
us to check if a condition is `True` and stop code execution if it is not.

```{python error=TRUE}
assert 1 == 0
print('This is only printed if the assertion above is "True"')
```

Since the condition above is `False`, an `AssertionError` is raised and code
execution halts. If the assertion is `True`, there is no output and the next
line of code is executed (if there is one).

```{python}
assert 0 == 0
print('This is only printed if the assertion above is "True"')
```

As mentioned above, this is useful if we know that a variable should look a
certain way, since we can assert if this is the case and guard ourselves from
errors that originate early in the pipeline but could give rise to more cryptic
errors that are difficult to troubleshoot later in the pipeline.

It is often helpful to add a clarifying message to the assertion statement,
especially as assertions become more complex.

```{python error=TRUE}
x = 1
assert x == 0, 'x is not 0'
```

Note that similar functionality can be achieved by explicitly raising an error
within a `try` and `except` block, or within a conditional statement using
`if`, `elif`, and `else`, but `assert` is a simple and readable way of allowing
for manual error checking.

## Packages {#r-dev-packages}

### Installing Python {#r-dev-installing-Python}

There are several ways of installing Python on your system. One of the most
robust and cross-platform compatible is to install the Anaconda Python
distribution, which is [available for Linux, macOS and
Windows](https://www.anaconda.com/distribution/#download-section). Choose to
download the Python 3 installer unless you need to work with Python 2 for a
specific reason.

### Using Python {#r-dev-using-Python}

When the Anaconda installation has finished, Python is accessible by running
`python` in a terminal (on Windows, use the `Anaconda Prompt`). Anaconda also
includes graphical interfaces for interacting with Python, which can be invoked
by running `spyder` or `jupyter-lab` from the command line, these are covered
more in detail elsewhere in this book.

### What is a package? {#r-dev-what-is-a-package}

A package is essentially a few Python scripts in a specific directory structure 
coupled with installation instructions for the computer. Python packages can 
come from various sources.  Many that you will use are part of the standard distribution, but packages can be created by anyone and there are thousands of that can be downloaded and installed from online repositories.  Note that you will sometimes hear packages referred 
to as "modules". The two words are often used interchangeably. Technically, 
a package is a folder that contains modules (scripts), which in turn contains functions (code).

Certain functionality that is considered essential for the Python programming language is available wherever Python is installed. This is the Python Standard Library, which is [maintained by the core language team][pep13].  Anything you see within the [Python documentation pages][py-docs] is part of the standard library.  Other highly useful, but often more domain specific functionality can be accessed separately in the
form of Python packages from third party developers. 

People around the world have created packages for Python and made them freely
available for others to use resulting in one of the richest package ecosystems
for any programming language, with packages for web design, prose writing, game
development, and data science (to name just a few). Since there are so many
packages available, it is not feasible to include all of them with the default
Python installation (it would be as if your new phone came with every single
app from the app/playstore preinstalled). Instead, Python packages can be
downloaded from central repositories online and installed as needed. The two
main repositories are the Python Package Index (PyPi) and the Anaconda package
repository. Instead of navigating to these sites with a web browser,
downloading the desired packages and installing them manually, there are so
called package managers that automate these processes. The package manager for
PyPi is called `pip` and the package manager for Anaconda is called `conda`. To
install a package either of these can be used, below is an example of what to
type on the command line to install the **num**erical **py**thon package
`numpy`.

```bash
conda install numpy
```

```bash
pip install numpy
```

Uninstalling a package is equally simple

```bash
conda remove numpy
```

```bash
pip uninstall numpy
```

Since we have downloaded the Anaconda Python distribution, we will
predominantly be using the `conda` package manager. Installing packages with
both interchangeably works, but it is recommended to stick to one as much as
possible. The Anaconda team has already bundled many commonly used packages
together with their Python installer, including most of the common data science
packages, such as `numpy` and `pandas`.

Now that you know how to access many of the world's best data science
packages right from your terminal, let's see how we can use them!

> Pro tip: Some packages are not available in the default Anaconda repositories. User
   contributed packaged are available in Anaconda "channels", use `anaconda
   search -t conda <package name>`, to find a channel with the desired package.
   To install this package, use `conda install -c <channel name> <package
   name>`. The [conda forge channel](https://conda-forge.github.io/) channel
   has many of the packages not in the default repositories.

### Importing packages {#r-dev-importing-packages}

Many of the functions that we use regularly, such as `print()` and `len()` are 
part of Python's Built-in functions. These are the functions that are always avaliable, 
but often our programs will need tools beyond these built-ins. Importing in this 
sense means that you are asking your program to "opt-in" to using that package's content.  
The syntax for importing content is the same for stardand library packages, third 
party packages, and local custom files. The lack of difference in syntax means that 
code can become confusing if you aren't extremely conversant in many of the packages.  
This is where good documentation comes in.

Import statements are generally found at the beginning of script or notebook files.  
Note that many of these examples will talk about importing functions, but there are 
several other types of content that can be imported from a package. 

There are two main ways of importing content:

1. `import <package_name>`: Import the entire package, giving you access to the 
package content by way of the package's name. E.g. `<package_name>.<function_name>()`.
2. `from <package_name> import <function_name>`: Import the entire package, but only define variables for the functions you list explicitly.
This gives you access to the imported content 
without having to specify the package name. E.g. `function_name()`.

Each of these methods has a way of renaming the package or content name to shorten 
it or in case there are multiple with the same name and you need to avoid namespace clashes. 
This is done using the `as` keyword, which is described in detail later in this chapter.

Any installed package can be accessed by typing `import <package_name>` in Python, e.g.

```{python}
import numpy
```

After importing a Python package, we can access any of its functions, by first
writing the followed by a period and then the function name, e.g.

```{python}
numpy.mean([1, 2, 3])
```

You can think of this as navigating to the numpy menu in a GUI software, and
then clicking the function you want. You don't need to recall every function
name by hard, pressing the <kbd>TAB</kbd> key after the period, will bring up
all available function and intelligently filter them as you type out more
letters, try it! When you start getting familiar with typing function names,
you will notice that this is often faster than looking for functions in menus.

It is common to give packages shorter nicknames, which are faster to type. This
is not necessary, but can save work in long files and make code less verbose so
that it is easier to read:

```{python}
import numpy as np

np.mean([1, 2, 3])
```
Using this syntax makes the variable `numpy` not defined in the current namespace. 

We could also import the mean function directly. Be careful, importing functions 
this way may cause name clashing and make your code harder to read because it isn't 
clear where that function came from.

```{python}
from numpy import mean

mean([1, 2, 3])
```

And even give it a nickname.

```{python}
from numpy import mean as mn

mn([1, 2, 3])
```

Which of these you use is up to you, but it is common to follow the conventions
established by the library's authors, which for numpy is `import numpy as np`
and use functions via `np.<function_name>`. Following community conventions means 
that your code will align with common documentation resources and will be understandable to other users of that tool.

One thing to avoid is to import everything from a package, e.g. `from numpy import *`. 
If this is done with every package, it is almost guaranteed that the same function name 
will be available from more than one package and it will be difficult to keep track of it 
if you are using the `mean` function from `numpy` or from another package that you also 
imported everything from.

Subpackages and their functions can be imported via the dot syntax.

```{python}
from numpy.fft import fftfreq
```

Packages and subpackages might sound complicated to keep apart. It can be
helpful to understand that they are folders and files in specific directory
structure. Considering only the `numpy` packages we have mentioned so far, the
directory structure would look like this.

```
numpy-folder/
    script-with-the-mean-definition.py
    fft-folder/
        script-with-the-fftfreq-definition.py
```

### Installing packages {#r-dev-installing-packages}

After Anaconda has been installed on your system, you can use the command line
`conda` package manager or the GUI-driven `anaconda-navigator` to install
Python packages. For comprehensive instructions on both of these, refer to the
[official
documentation](https://docs.continuum.io/anaconda/#navigator-or-conda). Brief
step-by-step instructions to get up and running with `conda` follow.

1. To install a new Python package from the Anaconda repositories, simply run
   `conda install <package name>` in a terminal. You can also use the `pip`
   package manager, but it will be easier to keep track of packages by sticking
   to one installation method.
2. Some packages are not available in the default Anaconda repositories. User
   contributed packaged are available in Anaconda "channels", use `anaconda
   search -t conda <package name>`, to find a channel with the desired package.
   To install this package, use `conda install -c <channel name> <package
   name>`. The [conda forge channel](https://conda-forge.github.io/) channel
   has many of the packages not in the default repositories.

## How to get help online {#r-dev-how-to-get-help-online}

When reading the built-in Python help is not sufficient, there are several
online resources that can helpful. One of the most commonly used resources for
data science is the Stack Exchange network which offer Q&A sites both for
programming related topics via [Stack Overflow][so], as well as statistics and
machine learning via [Cross Validated][cv].

If nothing relevant can be found after searching the many existing question and
answers on these sites, it is appropriate to ask a new question! Stack Overflow
has detailed instruction on how to create a [minimal reproducible
example][so-mre] when asking a question to increase the chances that the
question receives a specific and helpful answer. The key principles listed on
the website recommends that an answer follows these guidelines:

> - Minimal – Use as little code as possible that still produces the same
> problem
> - Complete – Provide all parts someone else needs to reproduce your problem
> in the question itself
> - Reproducible – Test the code you're about to provide to make sure it
> reproduces the problem

An additional benefit of reducing the problem into this format is that you
might discover the error in the process! This process helps narrowing down
exactly which region of the code is failing and the act of explaining the
problem often reveals a solution before any replies have come in (commonly
referred to as [rubber duck debugging][wiki-rubber-duck-debugging].

## Key Points {#r-dev-keypoints}

```{r child="keypoints/r-development.md"}
```

## Exercises {#r-dev-exercises}

1. Write a function that returns the mean of exactly two numbers. Start with
   the code we used to create the function `sum_two_numbers()` above.
2. Write a function that returns the mean of any amount of numbers. Start with
   the code we used to create the function `sum_and_len_all_numbers()` above.
3. Write a function that takes a string as its input and returns a tuple with
   the first and last character of the string.
4.
    a. Write a function that takes a string as its input and can return any
       single character. Which character is returned should be determined by
       an integer passed to a parameter called `character_index` which has the
       default value of `0`.
    b. Expand on the previous function by including an assert statement that
       checks if the integer given to the `character_index` parameter is within
       the length of the string.
    c. Describe the pros and cons of the ducktyping approach in `4a` and the
       explicit assert approach in `4b`.

## Creating functions


It's also good practice to add some formal documentation to the function. Use
the "Insert Roxygen Skeleton" in the "Code" menu list (or by typing
`Ctrl-Shift-Alt-R`) and you can add template documentation right above the
function. It looks like:

```{r roxygen-docs-1}
#' Title
#'
#' @param num1 
#' @param num2 
#'
#' @return
#' @export
#'
#' @examples
add_nums <- function(num1, num2) {
    added <- num1 + num2
    return(added)
}
```

In the `Title` area, this is where you type out a brief sentence or several words 
that describe the function. Creating a new paragraph below this line allows you 
to add a more detailed description. The other items are:

- `@param num` lines are to describe what each argument is for.
- `@return` describes what output the function provides. Is it a data.frame? A plot? 
What else does the output give?
- `@export` tells R that this function should be accessible to the user of your
package. Delete it for non-package functions.
- `@examples` lines below this are used to show examples of how to use the function.
Very useful when making packages, but not really in this case.

```{r roxygen-docs-2}
#' Add two numbers together.
#'
#' This is just an example function to show how to create one.
#'
#' @param num1 A number here.
#' @param num2 A number here.
#'
#' @return Returns the sum of the two numbers.
#'
add_nums <- function(num1, num2) {
    added <- num1 + num2
    return(added)
}
```

### Functions to wrangle

Let's get to something you might actually do in a data analysis project. Let's 
suppose you want to compare the mean and standard deviation of several variables
by a given categorical variable, such as `SurveyYr` or `Gender`, that you might
want to include as an exploratory table in a report or document. Without making 
a function, you would normally run a series of functions for each of the categorical
variables. For instance:

```{r to-wrangle}
NHANES %>% 
    select(Gender, BMI, TotChol, Pulse, BPSysAve, BPDiaAve) %>% 
    gather(Measurement, Value, -Gender) %>% 
    na.omit() %>% 
    group_by(Gender, Measurement) %>% 
    summarise(Mean = round(mean(Value), 2),
              SD = round(sd(Value), 2),
              MeanSD = str_c(Mean, " (", SD, ")")) %>% 
    select(-Mean, -SD) %>% 
    spread(Gender, MeanSD)
```

Nice, but now if we did it for `SurveyYr` instead of `Gender`? We would have to 
replace all `Gender` variables with `SurveyYr`. Instead, let's create a function.
First, copy and paste the code above into a function structure.

```{r base-function-template, eval=FALSE}
mean_sd_by_group <- function() {
    by_group_output <- NHANES %>% 
        select(Gender, BMI, TotChol, Pulse, BPSysAve, BPDiaAve) %>% 
        gather(Measurement, Value, -Gender) %>% 
        na.omit() %>% 
        group_by(Gender, Measurement) %>% 
        summarise(Mean = round(mean(Value), 2),
                  SD = round(sd(Value), 2),
                  MeanSD = str_c(Mean, " (", SD, ")")) %>% 
        select(-Mean, -SD) %>% 
        spread(Gender, MeanSD)
    return(by_group_output)
}
```

Great, now we need to add in arguments and place the arguments in the correct 
locations. (I tend to put a `.` before my arguments to differentiate them from 
other variables.)

```{r add-function-arguments, error=TRUE}
mean_sd_by_group <- function(.dataset, .groupvar) {
    by_group_output <- .dataset %>% 
        select(.groupvar, BMI, TotChol, Pulse, BPSysAve, BPDiaAve) %>% 
        gather(Measurement, Value, -.groupvar) %>% 
        na.omit() %>% 
        group_by(.groupvar, Measurement) %>% 
        summarise(Mean = round(mean(Value), 2),
                  SD = round(sd(Value), 2),
                  MeanSD = str_c(Mean, " (", SD, ")")) %>% 
        select(-Mean, -SD) %>% 
        spread(.groupvar, MeanSD)
    return(by_group_output)
}
mean_sd_by_group(NHANES, Gender)
```

What happened? We had an error. We've encountered a problem due to
"[non-standard evaluation]" (or NSE). NSE is very commonly used in most tidyverse
packages as well as throughout base R. It's one of the first things computer 
scientists complain about when they use R, because it is such a foreign thing
in other programming languages. But NSE is what allows you to use formulas (e.g.
`y ~ x + x2` in modelling) or allows you to type out `select(Gender, BMI)`. In
other programming languages, it would be `select("Gender", "BMI")`. It gives a lot
of flexibility to use for doing data analysis, but can give some headaches when
programming in R. So instead we have to use quotes instead and use the `_at()` 
combined with `vars()` version of dplyr functions. The tidyr functions `gather`
and `spread` don't require these changes.

[non-standard evaluation]: http://adv-r.had.co.nz/Computing-on-the-language.html

```{r add-function-arguments-error, error=TRUE}
mean_sd_by_group <- function(.dataset, .groupvar) {
    by_group_output <- .dataset %>% 
        select_at(vars(.groupvar, BMI, TotChol, Pulse, BPSysAve, BPDiaAve)) %>% 
        gather(Measurement, Value, -.groupvar) %>% 
        na.omit() %>% 
        group_by_at(vars(.groupvar, Measurement)) %>% 
        summarise(Mean = round(mean(Value), 2),
                  SD = round(sd(Value), 2),
                  MeanSD = str_c(Mean, " (", SD, ")")) %>% 
        select(-Mean, -SD) %>% 
        spread(.groupvar, MeanSD)
    return(by_group_output)
}
mean_sd_by_group(NHANES, "Gender")
```

Now we can also use other categorical variables:

```{r use-other-category-vars}
mean_sd_by_group(NHANES, "SurveyYr")
mean_sd_by_group(NHANES, "Diabetes")
```

Nifty eh? If you want a fancy table when using R Markdown, use the
`kable::knitr` function.

```{r fancy-table}
mean_sd_by_group(NHANES, "Diabetes") %>% 
    knitr::kable(caption = "Mean and SD of some measurements by Diabetes status.")
```

A massive advantage of using functions is that if you want to make a change to all
your code, you can very easily do it in the R function and it will change all 
your other code too!

If you want to make sure that who ever uses your function will not use a wrong 
argument, you can use "defensive programming" via the `stopifnot()` function.
This forces the code to only work if `.groupvar` is a character (e.g. `"this"`)
argument.

```{r add-function-stopifnot}
mean_sd_by_group <- function(.dataset, .groupvar) {
    stopifnot(is.character(.groupvar))
    by_group_output <- .dataset %>% 
        select_at(vars(.groupvar, BMI, TotChol, Pulse, BPSysAve, BPDiaAve)) %>% 
        gather(Measurement, Value, -.groupvar) %>% 
        na.omit() %>% 
        group_by_at(vars(.groupvar, Measurement)) %>% 
        summarise(Mean = round(mean(Value), 2),
                  SD = round(sd(Value), 2),
                  MeanSD = str_c(Mean, " (", SD, ")")) %>% 
        select(-Mean, -SD) %>% 
        spread(.groupvar, MeanSD)
    return(by_group_output)
}
```

A good practice to use after you've created your function is to explicitly indicate 
which functions come from which package, since you shouldn't use `library` calls
in your function. We do this by using the `packagename::function_name` format 
(you don't need to do this for base R functions). Plus, let's add some
documentation! (`Ctrl-Alt-Shift-R`).

```{r explicit-function-call}
#' Calculate mean and standard deviation by a grouping variable.
#'
#' @param .dataset The dataset
#' @param .group_variable Variable to group by
#'
#' @return Output a data frame.
#'
mean_sd_by_group <- function(.dataset, .groupvar) {
    stopifnot(is.character(.groupvar))
    by_group_output <- .dataset %>% 
        dplyr::select_at(dplyr::vars(.groupvar, BMI, 
                                     TotChol, Pulse, BPSysAve, BPDiaAve)) %>% 
        tidyr::gather(Measurement, Value, -.groupvar) %>% 
        na.omit() %>% 
        dplyr::group_by_at(dplyr::vars(.groupvar, Measurement)) %>% 
        dplyr::summarise(Mean = round(mean(Value), 2),
                  SD = round(sd(Value), 2),
                  MeanSD = stringr::str_c(Mean, " (", SD, ")")) %>% 
        dplyr::select(-Mean, -SD) %>% 
        tidyr::spread(.groupvar, MeanSD)
    return(by_group_output)
}
```

### Functions to plot

Let's do this for plots too, since we'll likely be making lots of those! Let's
say we are doing multiple scatter plots, and we've already made a nice theme. 
But we want to create several scatter plots. The non-function code:

```{r scatter-plot}
ggplot(NHANES, aes(x = Height, y = Weight, colour = Gender)) +
    geom_point(size = 2, alpha = 0.3) +
    scale_colour_viridis_d(option = "B", begin = 0.2, end = 0.7) +
    theme_minimal() +
    theme(text = element_text(colour = "grey40"))
```

Like before, maybe we want to see the scatter plot by different variables. So let's 
get it into function form:

```{r plot-function-template, eval=FALSE}
plot_scatter_by_group <- function() {
    scatter_plot <- ggplot(NHANES, aes(x = Height, y = Weight, 
                                       colour = Gender)) +
        geom_point(size = 2, alpha = 0.3) +
        scale_colour_viridis_d(option = "B", begin = 0.2, end = 0.7) +
        theme_minimal() +
        theme(text = element_text(colour = "grey40"))
    return(scatter_plot)
}
```

Then let's add in the arguments.

```{r plot-function-arguments, eval=FALSE}
plot_scatter_by_group <- function(.dataset, .xvar, .yvar, .groupvar) {
    scatter_plot <- ggplot(.dataset, aes(x = .xvar, y = .yvar, 
                                         colour = .groupvar)) +
        geom_point(size = 2, alpha = 0.3) +
        scale_colour_viridis_d(option = "B", begin = 0.2, end = 0.7) +
        theme_minimal() +
        theme(text = element_text(colour = "grey40"))
    return(scatter_plot)
}
```


Like the dplyr code above, this function won't work because it also uses NSE, so
ggplot2 will be confused by the `x = .xvar` since it will think you are asking
for the `.xvar` column in the dataset. So, we need to change `aes()` to
`aes_string()` to force ggplot2 to read `.xvar` as a character string that is
the name of the column you want to plot.

```{r plot-function-aes-string}
plot_scatter_by_group <- function(.dataset, .xvar, .yvar, .groupvar) {
    scatter_plot <- ggplot(.dataset, aes_string(x = .xvar, y = .yvar, 
                                                colour = .groupvar)) +
        geom_point(size = 2, alpha = 0.3) +
        scale_colour_viridis_d(option = "B", begin = 0.2, end = 0.7) +
        theme_minimal() +
        theme(text = element_text(colour = "grey40"))
    return(scatter_plot)
}
plot_scatter_by_group(NHANES, "Height", "Weight", "Gender")
```

Let's add in the `stopifnot`, `ggplot2::` explicit calls, and the roxygen
documentation (`Ctrl-Alt-Shift-R`):

```{r plot-function-finish-up}
#' Create a scatter plot with colouring by categorical variable.
#'
#' @param .dataset Data to plot.
#' @param .xvar Variable for the x axis.
#' @param .yvar Variable for the y axis.
#' @param .groupvar The variable to group/color by.
#'
#' @return Creates a ggplot.
#'
plot_scatter_by_group <- function(.dataset, .xvar, .yvar, .groupvar) {
    stopifnot(is.character(.xvar), is.character(.yvar), is.character(.groupvar))
    scatter_plot <- 
        ggplot2::ggplot(.dataset, ggplot2::aes_string(x = .xvar, y = .yvar, 
                                                      colour = .groupvar)) +
        ggplot2::geom_point(size = 2, alpha = 0.3) +
        ggplot2::scale_colour_viridis_d(option = "B", begin = 0.2, end = 0.7) +
        ggplot2::theme_minimal() +
        ggplot2::theme(text = ggplot2::element_text(colour = "grey40"))
    return(scatter_plot)
}
```

Now we can do other plots easily:

```{r use-plot-function-multiple-times}
plot_scatter_by_group(NHANES, "BMI", "TotChol", "SurveyYr")
plot_scatter_by_group(NHANES, "Poverty", "BMI", "Education")
plot_scatter_by_group(NHANES, "BMI", "BPSysAve", "Diabetes")
```
